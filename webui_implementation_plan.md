# WebUI å¤šæ­¥éª¤æ¨ç†ä¸­é—´è¿‡ç¨‹æ˜¾ç¤ºå®ç°è®¡åˆ’

## æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº†å¦‚ä½•åœ¨WebUIä¸­å®ç°å¤šæ­¥éª¤æ¨ç†ä¸­é—´è¿‡ç¨‹çš„å®æ—¶æ˜¾ç¤ºã€‚è¿™ä¸ªåŠŸèƒ½å°†ä½¿ç”¨æˆ·èƒ½å¤Ÿåœ¨å¯¹è¯å†å²ä¸­çœ‹åˆ°æ¨ç†çš„æ¯ä¸ªæ­¥éª¤ï¼Œè€Œä¸ä»…ä»…æ˜¯æœ€ç»ˆç»“æœï¼Œä»è€Œæå‡ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿé€æ˜åº¦ã€‚

## å®ç°æ­¥éª¤

### 1. å¢å¼ºæ ¸å¿ƒæ¨ç†å¼•æ“ (llm_research/reasoning.py)

#### 1.1 æ·»åŠ ä»»åŠ¡åˆ†è§£äº‹ä»¶

```python
# åœ¨task_decompositionæ–¹æ³•ä¸­æ·»åŠ åˆ†è§£å¼€å§‹äº‹ä»¶
self._log({
    "type": "decomposition_start",
    "message": f"ğŸ” åˆ†æä»»åŠ¡: \"{task}\"\næ­£åœ¨å°†ä»»åŠ¡åˆ†è§£ä¸ºå­ä»»åŠ¡...",
    "task": task
})

# åœ¨éœ€è¦é‡è¯•æ—¶æ·»åŠ é‡è¯•äº‹ä»¶
self._log({
    "type": "decomposition_retry",
    "message": f"âš ï¸ ç”Ÿæˆçš„å­ä»»åŠ¡æ•°é‡ ({len(subtasks)}) è¿œè¶…æœ€å¤§æ­¥éª¤æ•° ({self.max_steps})\næ­£åœ¨é‡æ–°åˆ†è§£ä»»åŠ¡ (å°è¯• {retry_count}/{max_retries})...",
    "retry_count": retry_count,
    "max_retries": max_retries
})

# åœ¨åˆ†è§£å®Œæˆæ—¶æ·»åŠ å®Œæˆäº‹ä»¶
subtasks_formatted = "\n".join([f"{i+1}. {subtask}" for i, subtask in enumerate(subtasks)])
self._log({
    "type": "decomposition_complete",
    "message": f"ğŸ“‹ å·²å°†ä»»åŠ¡åˆ†è§£ä¸ºä»¥ä¸‹å­ä»»åŠ¡:\n{subtasks_formatted}",
    "subtasks": subtasks
})
```

#### 1.2 æ·»åŠ å­ä»»åŠ¡æ‰§è¡Œäº‹ä»¶

```python
# åœ¨execute_subtasksæ–¹æ³•ä¸­æ·»åŠ å­ä»»åŠ¡å¼€å§‹äº‹ä»¶
self._log({
    "type": "subtask_start",
    "message": f"\nğŸ”„ æ‰§è¡Œå­ä»»åŠ¡ {i+1}/{total_subtasks}: \"{subtask}\"\næ€è€ƒä¸­...",
    "subtask_index": i,
    "subtask": subtask,
    "total_subtasks": total_subtasks
})

# åœ¨éœ€è¦é‡è¯•æ—¶æ·»åŠ é‡è¯•äº‹ä»¶
self._log({
    "type": "subtask_retry",
    "message": f"ğŸ” é‡è¯•å­ä»»åŠ¡ {i+1} (å°è¯• {retry_count}/{max_retries})...",
    "subtask_index": i,
    "retry_count": retry_count,
    "max_retries": max_retries
})

# åœ¨éªŒè¯å­ä»»åŠ¡å‰æ·»åŠ éªŒè¯å¼€å§‹äº‹ä»¶
self._log({
    "type": "subtask_validation_start",
    "message": f"ğŸ” éªŒè¯å­ä»»åŠ¡ {i+1} æ˜¯å¦å®Œæˆ...",
    "subtask_index": i
})

# åœ¨å­ä»»åŠ¡å®Œæˆæ—¶æ·»åŠ å®Œæˆäº‹ä»¶
self._log({
    "type": "subtask_complete",
    "message": f"âœ… å­ä»»åŠ¡ {i+1}/{total_subtasks} å®Œæˆ",
    "subtask_index": i,
    "subtask": subtask,
    "response": response
})

# åœ¨å­ä»»åŠ¡æœªå®Œæˆæ—¶æ·»åŠ æœªå®Œæˆäº‹ä»¶
self._log({
    "type": "subtask_incomplete",
    "message": f"âŒ å­ä»»åŠ¡ {i+1}/{total_subtasks} æœªå®Œæˆ",
    "subtask_index": i,
    "subtask": subtask,
    "response": response
})

# åœ¨è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°æ—¶æ·»åŠ æœ€å¤§é‡è¯•äº‹ä»¶
self._log({
    "type": "subtask_max_retries",
    "message": f"âš ï¸ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries})ï¼Œä½¿ç”¨æœ€åä¸€æ¬¡ç»“æœ",
    "subtask_index": i,
    "subtask": subtask,
    "response": response
})
```

#### 1.3 æ·»åŠ ç»“æœèšåˆäº‹ä»¶

```python
# åœ¨aggregate_resultsæ–¹æ³•ä¸­æ·»åŠ èšåˆå¼€å§‹äº‹ä»¶
self._log({
    "type": "aggregation_start",
    "message": "ğŸ§© æ•´åˆæ‰€æœ‰å­ä»»åŠ¡ç»“æœ\nç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ...",
    "task": task,
    "subtasks_count": len(subtasks)
})

# åœ¨èšåˆå®Œæˆæ—¶æ·»åŠ å®Œæˆäº‹ä»¶
self._log({
    "type": "aggregation_complete",
    "message": "âœ¨ ä»»åŠ¡å®Œæˆ!",
    "result": aggregation
})
```

### 2. ä¿®æ”¹WebUIé€‚é…å™¨ (llm_research/webui/adapters/reasoning.py)

#### 2.1 æ·»åŠ chat_interfaceå‚æ•°

```python
def __init__(
    self,
    llm: BaseLLM,
    max_steps: int = 5,
    temperature: float = 0.7,
    web_search_enabled: bool = True,
    extract_url_content: bool = True,
    ws_handler: Optional[Callable[[Dict[str, Any]], None]] = None,
    chat_interface = None  # æ·»åŠ chat_interfaceå‚æ•°
):
    # ...
    self.chat_interface = chat_interface  # å­˜å‚¨chat_interfaceå¼•ç”¨
    # ...
```

#### 2.2 å®ç°enhanced_ws_handlerå‡½æ•°

```python
def solve_task(
    self,
    task: str,
    context: Optional[str] = None,
    max_tokens: Optional[int] = None,
    temperature: Optional[float] = None,
    max_retries: int = 3
) -> str:
    # ä¿å­˜åŸå§‹ws_handler
    original_ws_handler = self.reasoning.ws_handler
    
    def enhanced_ws_handler(log_data):
        # è°ƒç”¨åŸå§‹ws_handler
        if original_ws_handler:
            original_ws_handler(log_data)
        
        # å¦‚æœchat_interfaceå¯ç”¨ï¼Œåœ¨èŠå¤©å†å²ä¸­æ˜¾ç¤º
        if self.chat_interface:
            log_type = log_data.get("type")
            message = log_data.get("message", "")
            
            if log_type == "decomposition_start":
                # ä»»åŠ¡åˆ†è§£å¼€å§‹
                self.chat_interface.addMessage('system', f"ğŸ” {message}")
            
            elif log_type == "decomposition_complete":
                # ä»»åŠ¡åˆ†è§£å®Œæˆ
                self.chat_interface.addMessage('assistant', f"ğŸ“‹ {message}")
            
            elif log_type == "subtask_start":
                # å­ä»»åŠ¡å¼€å§‹
                subtask_index = log_data.get("subtask_index", 0)
                total_subtasks = log_data.get("total_subtasks", 1)
                subtask = log_data.get("subtask", "")
                self.chat_interface.addMessage('system', f"ğŸ”„ æ‰§è¡Œå­ä»»åŠ¡ {subtask_index+1}/{total_subtasks}: \"{subtask}\"")
            
            elif log_type == "subtask_complete":
                # å­ä»»åŠ¡å®Œæˆ
                response = log_data.get("response", "")
                self.chat_interface.addMessage('assistant', f"âœ… {message}\n\n{response}")
            
            elif log_type == "subtask_incomplete" or log_type == "subtask_retry":
                # å­ä»»åŠ¡æœªå®Œæˆæˆ–é‡è¯•
                self.chat_interface.addMessage('system', message)
            
            elif log_type == "aggregation_start":
                # èšåˆå¼€å§‹
                self.chat_interface.addMessage('system', message)
            
            elif log_type == "step_error" or log_type == "subtask_max_retries":
                # é”™è¯¯æˆ–è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
                self.chat_interface.addMessage('system', f"âŒ {message}")
            
            elif log_type == "log" and message.strip():
                # æ™®é€šæ—¥å¿—æ¶ˆæ¯
                self.chat_interface.addMessage('system', message)
    
    # ä¸´æ—¶æ›¿æ¢ws_handler
    self.reasoning.ws_handler = enhanced_ws_handler
    
    try:
        # æ‰§è¡Œä»»åŠ¡
        result = self.reasoning.solve_task(
            task=task,
            context=context,
            max_tokens=max_tokens,
            temperature=temperature or self.temperature,
            max_retries=max_retries
        )
        
        # å°†æœ€ç»ˆç»“æœæ·»åŠ åˆ°èŠå¤©
        if self.chat_interface:
            self.chat_interface.addMessage('assistant', f"âœ¨ æœ€ç»ˆç»“æœ:\n\n{result}")
        
        return result
    finally:
        # æ¢å¤åŸå§‹ws_handler
        self.reasoning.ws_handler = original_ws_handler
```

### 3. æ›´æ–°APIå’Œå‰ç«¯ä»£ç 

#### 3.1 ä¿®æ”¹APIç«¯ç‚¹ (llm_research/webui/api.py)

```python
# è·å–ä¼šè¯IDï¼ˆå¦‚æœæä¾›ï¼‰
conversation_id = data.get('conversation_id')

# è·å–èŠå¤©ç•Œé¢ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
chat_interface = None
if conversation_id and conversation_id in conversations:
    chat_interface = conversations[conversation_id]

# åˆ›å»ºæ¨ç†é€‚é…å™¨ï¼Œä¼ é€’èŠå¤©ç•Œé¢
reasoning = ReasoningAdapter(
    llm,
    max_steps=steps,
    web_search_enabled=web_search_enabled,
    extract_url_content=extract_url_content,
    ws_handler=send_log_to_client,
    chat_interface=chat_interface  # ä¼ é€’èŠå¤©ç•Œé¢
)
```

#### 3.2 æ›´æ–°å‰ç«¯APIå®¢æˆ·ç«¯ (llm_research/webui/static/js/api.js)

```javascript
// åœ¨startReasoningæ–¹æ³•ä¸­ä¼ é€’å½“å‰ä¼šè¯ID
async startReasoning(task, options = {}) {
    try {
        const response = await fetch(`${this.baseUrl}/api/reasoning`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                task: task,
                steps: options.steps || 5,
                provider: options.provider,
                temperature: options.temperature,
                max_tokens: options.max_tokens,
                web_search: options.web_search,
                extract_url: options.extract_url,
                retries: options.retries || 3,
                context_files: options.context_files || [],
                conversation_id: this.activeConversationId  // ä¼ é€’å½“å‰ä¼šè¯ID
            })
        });
        
        // ...
    } catch (error) {
        // ...
    }
}
```

#### 3.3 å®ç°å‰ç«¯æ—¥å¿—å¤„ç† (llm_research/webui/static/js/reasoning.js)

```javascript
/**
 * å¤„ç†æ¨ç†æ—¥å¿—äº‹ä»¶
 *
 * @param {Object} data - äº‹ä»¶æ•°æ®
 */
handleReasoningLog(data) {
    // å¤„ç†ç»“æ„åŒ–æ—¥å¿—æ¶ˆæ¯
    if (typeof data === 'object' && data.type) {
        // enhanced_ws_handlerä¼šå¤„ç†åœ¨èŠå¤©å†å²ä¸­æ˜¾ç¤ºè¿™äº›æ¶ˆæ¯
        // æˆ‘ä»¬åªéœ€è¦æ ¹æ®æ—¥å¿—ç±»å‹æ›´æ–°UI
        
        const message = data.message || '';
        
        // æ ¹æ®æ—¥å¿—ç±»å‹æ›´æ–°è¿›åº¦æ¡å’ŒçŠ¶æ€
        switch (data.type) {
            case 'decomposition_start':
                this.reasoningStatus.textContent = 'åˆ†æä»»åŠ¡ä¸­...';
                this.reasoningProgressBar.style.width = '10%';
                break;
                
            case 'decomposition_complete':
                this.reasoningStatus.textContent = 'ä»»åŠ¡åˆ†è§£å®Œæˆ';
                this.reasoningProgressBar.style.width = '20%';
                
                // å¦‚æœæœ‰å­ä»»åŠ¡ï¼Œæ›´æ–°å­ä»»åŠ¡
                if (data.subtasks && Array.isArray(data.subtasks)) {
                    this.subtasks = data.subtasks;
                    this.currentSubtaskIndex = 0;
                }
                break;
                
            case 'subtask_start':
                if (data.subtask_index !== undefined && data.total_subtasks) {
                    const progress = 20 + (data.subtask_index / data.total_subtasks) * 60;
                    this.reasoningProgressBar.style.width = `${progress}%`;
                    this.reasoningStatus.textContent = `æ‰§è¡Œå­ä»»åŠ¡ ${data.subtask_index + 1}/${data.total_subtasks}`;
                }
                break;
                
            case 'subtask_complete':
                if (data.subtask_index !== undefined && data.total_subtasks) {
                    const progress = 20 + ((data.subtask_index + 1) / data.total_subtasks) * 60;
                    this.reasoningProgressBar.style.width = `${progress}%`;
                    this.reasoningStatus.textContent = `å­ä»»åŠ¡ ${data.subtask_index + 1}/${data.total_subtasks} å®Œæˆ`;
                }
                break;
                
            case 'aggregation_start':
                this.reasoningProgressBar.style.width = '80%';
                this.reasoningStatus.textContent = 'æ•´åˆç»“æœä¸­...';
                break;
                
            case 'aggregation_complete':
                this.reasoningProgressBar.style.width = '100%';
                this.reasoningStatus.textContent = 'æ¨ç†å®Œæˆ';
                break;
        }
    } 
    // å¤„ç†ç®€å•å­—ç¬¦ä¸²æ—¥å¿—æ¶ˆæ¯ï¼ˆæ—§æ ¼å¼ï¼‰
    else if (typeof data === 'string' || data.message) {
        const message = typeof data === 'string' ? data : data.message;
        // åªæ·»åŠ éç©ºæ¶ˆæ¯ï¼Œé¿å…èŠå¤©å†å²æ··ä¹±
        if (message && message.trim()) {
            this.chatInterface.addMessage('system', message);
        }
    }
}
```

## æµ‹è¯•è®¡åˆ’

1. **åŸºæœ¬åŠŸèƒ½æµ‹è¯•**
   - æµ‹è¯•ç®€å•æ¨ç†ä»»åŠ¡ï¼Œç¡®ä¿æ‰€æœ‰ä¸­é—´æ­¥éª¤æ­£ç¡®æ˜¾ç¤º
   - éªŒè¯ä»»åŠ¡åˆ†è§£ã€å­ä»»åŠ¡æ‰§è¡Œå’Œç»“æœèšåˆçš„äº‹ä»¶æ˜¯å¦æ­£ç¡®æ˜¾ç¤º

2. **å¤æ‚åœºæ™¯æµ‹è¯•**
   - æµ‹è¯•åŒ…å«å¤šä¸ªå­ä»»åŠ¡çš„å¤æ‚æ¨ç†ä»»åŠ¡
   - æµ‹è¯•éœ€è¦é‡è¯•çš„åœºæ™¯ï¼Œç¡®ä¿é‡è¯•äº‹ä»¶æ­£ç¡®æ˜¾ç¤º
   - æµ‹è¯•è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°çš„åœºæ™¯

3. **é”™è¯¯å¤„ç†æµ‹è¯•**
   - æµ‹è¯•æ¨ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯å¤„ç†
   - éªŒè¯é”™è¯¯æ¶ˆæ¯æ˜¯å¦æ­£ç¡®æ˜¾ç¤ºåœ¨èŠå¤©å†å²ä¸­

4. **é›†æˆæµ‹è¯•**
   - æµ‹è¯•ä¸ç°æœ‰èŠå¤©åŠŸèƒ½çš„é›†æˆ
   - ç¡®ä¿æ¨ç†åŠŸèƒ½ä¸å½±å“å…¶ä»–åŠŸèƒ½çš„æ­£å¸¸å·¥ä½œ

## éƒ¨ç½²è®¡åˆ’

1. åœ¨å¼€å‘ç¯å¢ƒä¸­å®ç°å¹¶æµ‹è¯•æ‰€æœ‰æ›´æ”¹
2. è¿›è¡Œä»£ç å®¡æŸ¥ï¼Œç¡®ä¿ä»£ç è´¨é‡å’Œä¸€è‡´æ€§
3. åœ¨æµ‹è¯•ç¯å¢ƒä¸­éƒ¨ç½²å¹¶è¿›è¡Œå…¨é¢æµ‹è¯•
4. ä¿®å¤å‘ç°çš„ä»»ä½•é—®é¢˜
5. éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
6. ç›‘æ§ç³»ç»Ÿæ€§èƒ½å’Œç”¨æˆ·åé¦ˆ
7. æ ¹æ®åé¦ˆè¿›è¡Œå¿…è¦çš„è°ƒæ•´å’Œä¼˜åŒ–